#!/usr/bin/env csh

#=========================================================================#
#       Hydra job setup script for the collapse of 3 SQG vortices
#=========================================================================#

# Specify code numerical method class:
set meth="ca"
# Specify code geometry:
set geom="plane"
# Specify model equation type:
set equa="sqg"
# Specify type of algorithm:
set algo="caps"

#==========================================================================
# The following is totally generic!
set local_home=`homedir`
set hydradir=$local_home/$user/hydra/$meth/$geom/$equa

# Get output base directory:
set workdir=`workdir`
# Make the base data directory if it does not already exist:
if (!(-d $workdir)) mkdir $workdir
set workdir=$workdir/hydra
if (!(-d $workdir)) mkdir $workdir
set basedir=$workdir/$meth
if (!(-d $basedir)) mkdir $basedir
set basedir=$basedir/$geom
if (!(-d $basedir)) mkdir $basedir
set basedir=$basedir/$equa
if (!(-d $basedir)) mkdir $basedir
set basedir=$basedir/$algo
if (!(-d $basedir)) mkdir $basedir

set outdir=$workdir/$meth/$geom/$equa/$algo

# Assign source and binary directories:
set srcdir=$hydradir/$algo
set bindir=$hydradir/scripts

# Get the name of the computer to record in the job_info file below:
set host=`hostname | awk -F. '{print $(1)}'`

#==========================================================================
# generate a random number seed based on current time:
set second=`date +%-S`
set minute=`date +%-M`
set hour=`date +%-H`
set day=`date +%-d`
@ iseed = ( $second + ( 60 * ( $minute + 60 * ( $hour + ( 24 * $day ) ) ) ) )

# Create a temporary directory:
set tmpdir=$outdir/tmp{$iseed}
mkdir $tmpdir
cd $tmpdir

echo
echo ' *** Job will be built in the temporary directory '
echo $tmpdir

# Create a job information summary file:
touch job_info
echo ' Job created at                      ' `date` >> job_info
echo ' on                                  ' $host >> job_info
echo ' ' >> job_info

#==========================================================================
# Set up the vortex positions and strengths using collapse2.py in
# point vortex directory:
set pointdir=$local_home/$user/math/pointv/sqg/src

python3 $pointdir/collapse2.py
# This creates the files strengths.asc and coordinates.asc

# Extract the vortex strengths:
set kappa = `cat strengths.asc `

# Extract the vortex centres:
set junk = `cat coordinates.asc `
set xc=`cat strengths.asc `
set yc=`cat strengths.asc `
set xc[1]=$junk[2]
set yc[1]=$junk[3]
set xc[2]=$junk[4]
set yc[2]=$junk[5]
set xc[3]=$junk[6]
set yc[3]=$junk[7]

set dx=`echo "( $xc[2] - $xc[3] )" | bc -l`
set dy=`echo "( $yc[2] - $yc[3] )" | bc -l`
set s1sq=`echo "( $dx * $dx + $dy * $dy )" | bc -l`

set dx=`echo "( $xc[3] - $xc[1] )" | bc -l`
set dy=`echo "( $yc[3] - $yc[1] )" | bc -l`
set s2sq=`echo "( $dx * $dx + $dy * $dy )" | bc -l`

set dx=`echo "( $xc[1] - $xc[2] )" | bc -l`
set dy=`echo "( $yc[1] - $yc[2] )" | bc -l`
set s3sq=`echo "( $dx * $dx + $dy * $dy )" | bc -l`

set junk=`echo "( $s1sq * 1000000 )" | bc -l`
set i1=$junk:r

set junk=`echo "( $s2sq * 1000000 )" | bc -l`
set i2=$junk:r

set junk=`echo "( $s3sq * 1000000 )" | bc -l`
set i3=$junk:r

if ($i1 < $i2) then
    set imax=$i2
else
    set imax=$i1
endif

if ($imax < $i3) then
    set imax=$i3
endif

set smaxsq=`echo "( $imax / 1000000 )" | bc -l`
set smax=`echo "( sqrt($smaxsq) )" | bc -l`

echo
echo ' The maximum inter-vortex separation is ' $smax

#==========================================================================
# Numerical parameters:
set lxdpi = "2"     # L_x/pi
set dedpi  = "0.5"  # D / pi where D = N*H/f is the scaled depth
set nx = "1024"     # Inversion grid resolution in x (east - west)
set nq="100"        # Number of contours used to represent buoyancy
set tgsave="0.005"  # Grid data save time increment
set tcsave="0.05"   # Contour data save time increment
set tsim="1.0"      # Total simulation time

#==========================================================================
# Set fixed constants:
set pi=3.14159265358979323846

#==========================================================================
# Choose main physical parameters:
echo
echo -n ' Width of the domain in x divided by pi, L_x/pi (default' $lxdpi')? '
set var=$<
if ($var != "") set lxdpi=$var

set ellx=`echo "$lxdpi * $pi" | bc -l`
# square domain:
set elly=$ellx

echo ' Width of the domain in x, L_x:      ' $lxdpi"*pi" >> job_info
echo ' Width of the domain in y, L_y:      ' $lxdpi"*pi" >> job_info

echo -n ' Enter D/pi where D = N*H/f is the scaled depth (default' $dedpi')? '
set var=$<
if ($var != "") set dedpi=$var
set depth=`echo "$dedpi * $pi" | bc -l`

#==========================================================================
# Choose numerical parameters:
echo
echo -n ' Grid resolution in x (default' $nx')? '
set var=$<
if ($var != "") set nx=$var
echo ' Inversion grid resolution in x:     ' $nx >> job_info

# Set y resolution the same:
set ny=$nx
echo ' Inversion grid resolution in y:     ' $ny >> job_info

echo -n ' No. of jumps to represent the buoyancy variation (default' $nq')? '
set var=$<
if ($var != "") set nq=$var
echo ' Number of buoyancy jumps, nq:       ' $nq >> job_info

echo
echo -n ' Time interval between gridded data saves (default' $tgsave')? '
set var=$<
if ($var != "") set tgsave=$var
echo ' Time interval between data saves:   ' $tgsave >> job_info

echo -n ' Time interval between contour data saves (default' $tcsave')? '
set var=$<
if ($var != "") set tcsave=$var
echo ' Time interval between contour saves:' $tcsave >> job_info

echo -n ' Total simulation time (default' $tsim')? '
set var=$<
if ($var != "") set tsim=$var
echo ' Total simulation time:              ' $tsim >> job_info
echo ' ' >> job_info

# Use default values for hyperviscosity (applied to residual buoyancy only):
set nnu=3
set cdamp="2.0"

echo ' ' >> job_info
echo ' ***Lap^'{$nnu} 'Hyperdiffusion on buoyancy     ' >> job_info
echo ' C*|zeta|_rms = damping rate for k = k_max/2   ' >> job_info
echo ' Damping coefficient, C:             ' $cdamp >> job_info

#============================================================
# Build parameter file with cpp and make all codes:

# Put all these dimensions into the parameter file needed for compilation:
mkdir src
cd src
cp $srcdir/* .
cp -r $hydradir/init .
cp -r $hydradir/post .

echo 
echo " Compiling source files....."
echo " -----------------------------------------------------------------------"

# Use C pre-processor to put chosen parameters $copts into parameters.f90
set copts1="-DN_X=$nx -DN_Y=$ny -DN_CONTQ=$nq -DT_SIM={$tsim}d0 -DT_GSAVE={$tgsave}d0 -DT_CSAVE={$tcsave}d0"
set copts2="-DL_X={$ellx}d0 -DL_Y={$elly}d0 -DL_Z={$depth}d0 -DC_DAMP={$cdamp}d0 -DPOW_HYPER=$nnu"
set copts=`echo $copts1 $copts2`

precomp $copts parameters.f90

# Compile all codes and move sources to sub-directory:
make $algo setup collapse proxy_post_all install clean

cd ..
echo " -----------------------------------------------------------------------"
echo 

#============================================================
# Execute the data generation script:
$bindir/collapse

#==========================================================================
# Create a directory named after the data generation script:
cd ..
if (!(-d collapse)) mkdir collapse
cd collapse

# Set the job directory name (will be appended by 001, 002 etc...):
set basejobdir=nx{$nx}dopi{$dedpi}

echo
echo -n ' Job directory name (default '{$basejobdir}')? '
set var=$<
if ($var != "") set basejobdir=$var

# work out the last run which has been performed:
# First make a bogus empty directory so this works!
mkdir {$basejobdir}r000
set last_run = `/bin/ls -d {$basejobdir}r??? | tail -c 4 | head -c 3`
rmdir {$basejobdir}r000

@ next_run = ( $last_run + 1 )
@ p1 = ( $next_run / 100 )
@ jr = ( $next_run - ( 100 * $p1 ) )
@ p2 = ( $jr / 10 )
@ p3 = ( $jr - ( 10 * $p2 ) )
set pind={$p1}{$p2}{$p3}

set jobdir={$basejobdir}r{$pind}

#=============================================================
# Lastly move all data to desired job directory:

# Move temporary directory to job directory:
mv $tmpdir $jobdir
cd $jobdir
set datadir=`pwd`

# Copy handy scripts for imaging:
/bin/cp $bindir/dv .
/bin/cp $bindir/ddv .
/bin/cp $bindir/sv .
/bin/cp $bindir/pfields .
/bin/cp $bindir/pevo .
/bin/cp $bindir/pnorms .
/bin/cp $bindir/pbbpp .

echo ' ' >> job_info
echo ' Job directory:' >> job_info
echo $datadir >> job_info

echo ' To set the job running, type'
echo cd $datadir
echo bat log $algo
echo
